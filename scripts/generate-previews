#!/usr/bin/env python3
from collections import OrderedDict
from datetime import datetime
from fnmatch import fnmatch
from itertools import chain
import argparse
import glob
import hashlib
import json
import logging
import os
import re
import subprocess
import sys

logger = logging.getLogger(__name__)
log_handler = logging.StreamHandler(sys.stdout)
log_handler.setLevel(logging.INFO)
logger.addHandler(log_handler)
logger.setLevel(logging.INFO)

arg_parser = argparse.ArgumentParser(description='Generates file previews from a JSON history, removes old previews.')
arg_parser.add_argument(
    'input_json',
    help='The JSON history file to read',
    type=str,
)
arg_parser.add_argument(
    'output_dir',
    help='The output directory where the previews will be saved',
    type=str,
)
arg_parser.add_argument(
    '--preview-height',
    default=120,
    help='The height of preview images/videos',
    type=str,
)
args = arg_parser.parse_args()

assert os.path.isfile(args.input_json)
assert os.path.isdir(args.output_dir)


def get_history_file_list(json_history_path: str):
    with open(json_history_path, 'r') as json_file:
        history = json.load(json_file)

    # Flatten the history (it's a {date: entries[]} dictionary)
    return chain(*history['entries'].values())


def get_parent_schema(schema):
    return '.'.join(schema.split('.')[:-1])


def generate_video_preview(previews_dir: str, file: dict):
    logger.info(f"Generating video preview for {file['path']}")
    preview_path = os.path.abspath(os.path.join(previews_dir, f"{file['checksum']}.jpg"))

    ffprobe_cmd = subprocess.run(
        ['ffprobe', '-show_streams', file['path']],
        stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    ffprobe_output = ffprobe_cmd.stdout.decode('utf-8')
    try:
        total_frame_count = int(re.search('nb_frames=([0-9]+)', ffprobe_output).group(1))
    except AttributeError:  # Frame count is "N/A"
        return  # There are other ways to get frame count: https://www.binpress.com/generate-video-previews-ffmpeg/

    preview_frame_count = 10
    frame_interval = total_frame_count // preview_frame_count
    frame_height = args.preview_height

    ffmpeg_cmd = subprocess.run(
        [
            'ffmpeg',
            '-y',
            '-i', file['path'],
            '-frames', '1',
            '-q:v', '1',
            '-vf', f'select=not(mod(n\,{frame_interval})),scale=-1:{frame_height},tile={preview_frame_count}x1',
            preview_path
        ],
        stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )


def generate_image_preview(previews_dir: str, file: dict):
    logger.info(f"Generating image preview for {file['path']}")
    preview_path = os.path.abspath(os.path.join(previews_dir, f"{file['checksum']}.jpg"))
    frame_height = args.preview_height
    ffmpeg_cmd = subprocess.run(
        [
            'ffmpeg',
            '-y',
            '-i', file['path'],
            '-vf', f'scale=-1:{frame_height}',
            preview_path
        ],
        stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    print(ffmpeg_cmd.stderr.decode('utf-8'))


preview_strategies = {
    'file.image': generate_image_preview,
    'file.video': generate_video_preview,
}


def get_preview_strategy(schema):
    return preview_strategies.get(schema, None) or preview_strategies.get(get_parent_schema(schema), None)


def generate_preview(previews_dir: str, file: dict):
    preview_strategy = get_preview_strategy(file['schema'])
    preview_strategy(previews_dir, file)


def generate_previews(json_history_path: str, previews_dir: str):
    """Generate new previews, deletes obsolete previews"""
    files = get_history_file_list(json_history_path)

    required_previews = [file for file in files if get_preview_strategy(file['schema'])]
    existing_previews = [os.path.basename(file_path) for file_path in os.scandir(previews_dir)]

    checksum_to_required_preview = {
        file['checksum']: file
        for file in required_previews
    }
    checksum_to_existing_preview = {
        os.path.splitext(file_path)[0]: file_path
        for file_path in existing_previews
    }

    required_checksums = checksum_to_required_preview.keys()
    existing_checksums = checksum_to_existing_preview.keys()

    new_checksums = required_checksums - existing_checksums
    obsolete_checksums = existing_checksums - required_checksums
    unchanged_checksums = existing_checksums - obsolete_checksums

    for checksum in new_checksums:
        generate_preview(previews_dir, checksum_to_required_preview[checksum])

    for checksum in obsolete_checksums:
        preview_path = os.path.join(previews_dir, checksum_to_existing_preview[checksum])
        os.remove(preview_path)

    logger.info(f"{len(new_checksums)} previews created, {len(obsolete_checksums)} deleted, {len(unchanged_checksums)} not changed")


def to_json_datetime(datetime):
    return datetime.isoformat()[:19]


def generate_checksum(path):
    with open(path, "rb") as f:
        file_hash = hashlib.blake2b()
        while chunk := f.read(8192):
            file_hash.update(chunk)
    return file_hash.hexdigest()


generate_previews(args.input_json, args.output_dir)