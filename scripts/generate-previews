#!/usr/bin/env python3
from collections import OrderedDict
from datetime import datetime
from fnmatch import fnmatch
from itertools import chain
import argparse
import glob
import hashlib
import json
import logging
import os
import sys

logger = logging.getLogger(__name__)
log_handler = logging.StreamHandler(sys.stdout)
log_handler.setLevel(logging.INFO)
logger.addHandler(log_handler)
logger.setLevel(logging.INFO)

arg_parser = argparse.ArgumentParser(description='Generates file previews from a JSON history, removes obsolete previews.')
arg_parser.add_argument(
    'input_json',
    help='The JSON history file to read',
    type=str,
)
arg_parser.add_argument(
    'output_dir',
    help='The output directory where the previews will be saved',
    type=str,
)
args = arg_parser.parse_args()

assert os.path.isfile(args.input_json)
assert os.path.isdir(args.output_dir)


def get_history_file_list(json_history_path: str):
    with open(json_history_path, 'r') as json_file:
        history = json.load(json_file)

    # Flatten the history (it's a {date: entries[]} dictionary)
    return chain(*history['entries'].values())


def get_parent_schema(schema):
    return '.'.join(schema.split('.')[:-1])


def generate_audio_preview(previews_dir: str, file: dict):
    logger.info(f"Generating audio preview for {file['path']}")
    file_path = os.path.join(previews_dir, f"{file['checksum']}.mp3")
    os.close(os.open(file_path, os.O_CREAT))


def generate_video_preview(previews_dir: str, file: dict):
    logger.info(f"Generating video preview for {file['path']}")
    file_path = os.path.join(previews_dir, f"{file['checksum']}.mp4")
    os.close(os.open(file_path, os.O_CREAT))


def generate_image_preview(previews_dir: str, file: dict):
    logger.info(f"Generating image preview for {file['path']}")
    file_path = os.path.join(previews_dir, f"{file['checksum']}.jpg")
    os.close(os.open(file_path, os.O_CREAT))


preview_strategies = {
    'file.audio': generate_audio_preview,
    'file.image': generate_image_preview,
    'file.video': generate_video_preview,
}


def get_preview_strategy(schema):
    return preview_strategies.get(schema, None) or preview_strategies.get(get_parent_schema(schema), None)


def generate_preview(previews_dir: str, file: dict):
    preview_strategy = get_preview_strategy(file['schema'])
    preview_strategy(previews_dir, file)


def generate_previews(json_history_path: str, previews_dir: str):
    """Generate new previews, deletes obsolete previews"""
    files = get_history_file_list(json_history_path)

    required_previews = [file for file in files if get_preview_strategy(file['schema'])]
    existing_previews = [os.path.basename(file_path) for file_path in os.scandir(previews_dir)]

    checksum_to_required_preview = {
        file['checksum']: file
        for file in required_previews
    }
    checksum_to_existing_preview = {
        os.path.splitext(file_path)[0]: file_path
        for file_path in existing_previews
    }

    required_checksums = checksum_to_required_preview.keys()
    existing_checksums = checksum_to_existing_preview.keys()

    new_checksums = required_checksums - existing_checksums
    obsolete_checksums = existing_checksums - required_checksums
    unchanged_checksums = existing_checksums - obsolete_checksums

    for checksum in new_checksums:
        generate_preview(previews_dir, checksum_to_required_preview[checksum])

    for checksum in obsolete_checksums:
        preview_path = os.path.join(previews_dir, checksum_to_existing_preview[checksum])
        os.remove(preview_path)

    logger.info(f"{len(new_checksums)} previews created, {len(obsolete_checksums)} deleted, {len(unchanged_checksums)} not changed")


def to_json_datetime(datetime):
    return datetime.isoformat()[:19]


def generate_checksum(path):
    with open(path, "rb") as f:
        file_hash = hashlib.blake2b()
        while chunk := f.read(8192):
            file_hash.update(chunk)
    return file_hash.hexdigest()


generate_previews(args.input_json, args.output_dir)